{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "path = \"/home/ubuntu/xiaokang/big_data_study/data/weibo_process/weibo_output/weibo_text_clean_parquet_daily_city_coded\"\n",
    "file_list = glob.glob(path+\"/weibo_text_clean_China_2023*.parquet\")\n",
    "print(len(file_list))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for file in tqdm.tqdm(file_list):\n",
    "    df = pd.read_parquet(file)\n",
    "    data = pd.concat([data,df])\n",
    "\n",
    "# 俄亥俄\n",
    "# 化学品泄漏\n",
    "# 有毒气泄漏\n",
    "# 毒气体泄漏\n",
    "# 氯乙烯泄漏\n",
    "# 毒火车事件\n",
    "# 毒火车\n",
    "key_words = [\"俄亥俄\",\"化学品泄漏\",\"有毒气泄漏\",\"毒气体泄漏\",\"氯乙烯泄漏\",\"毒火车事件\",\"毒火车\"]\n",
    "data = data[data.text.str.contains(\"|\".join(key_words))]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
